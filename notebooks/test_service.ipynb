{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #! specify gpu here\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import random\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "# import vision_pipeline.obb\n",
    "# import imagesize\n",
    "# from scipy import ndimage\n",
    "import natsort\n",
    "from PIL import Image as PILImage\n",
    "# from PIL import ImageDraw, ImageFilter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from shapely.geometry import Polygon\n",
    "from rich import print\n",
    "# from types import SimpleNamespace\n",
    "import pickle\n",
    "import imutils\n",
    "\n",
    "# ros package\n",
    "from context_action_framework.types import Detection, Label, Module, Camera, detections_to_ros, detections_to_py\n",
    "from sensor_msgs.msg import Image, CameraInfo # CameraInfo needed for pickle\n",
    "\n",
    "from context_action_framework.srv import VisionDetection, VisionDetectionResponse, VisionDetectionRequest, ProcessImg, ProcessImgResponse\n",
    "\n",
    "from cv_bridge import CvBridge\n",
    "import rospy\n",
    "\n",
    "\n",
    "\n",
    "# # local imports\n",
    "# from vision_pipeline.helpers import Struct, make_valid_poly, img_to_camera_coords\n",
    "# from action_predictor.graph_relations import GraphRelations, exists_detection, compute_iou\n",
    "# from vision_pipeline.work_surface_detection_opencv import WorkSurfaceDetection\n",
    "# from vision_pipeline.object_detection_model import ObjectDetectionModel\n",
    "# from vision_pipeline.object_detection import ObjectDetection\n",
    "# from vision_pipeline.object_reid import ObjectReId\n",
    "\n",
    "# from vision_pipeline.config import load_config\n",
    "\n",
    "# from vision_pipeline.object_reid_superglue import ObjectReIdSuperGlue\n",
    "\n",
    "rospy.init_node(\"test_node\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: call a service to get info about image\n",
    "\n",
    "img_path = os.path.expanduser(\"~/datasets2/reconcycle/2023-08-01_basler_hca_backs/0001.jpg\")\n",
    "\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = imutils.resize(img, width=1450, height=1450)\n",
    "\n",
    "\n",
    "# display(PILImage.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_process_img(img):\n",
    "    timeout = 3 # 2 second timeout\n",
    "    rospy.wait_for_service('vision/basler/process_img', timeout)\n",
    "\n",
    "    imgmsg = CvBridge().cv2_to_imgmsg(img, encoding=\"bgr8\")\n",
    "    try:\n",
    "        process_img = rospy.ServiceProxy('vision/basler/process_img', ProcessImg)\n",
    "        response = process_img(imgmsg)\n",
    "        detections = detections_to_py(response.detections)\n",
    "        labelled_img = CvBridge().imgmsg_to_cv2(response.labelled_image, desired_encoding='passthrough')\n",
    "        \n",
    "        return response.success, detections, labelled_img\n",
    "        # return response\n",
    "    except rospy.ServiceException as e:\n",
    "        print(\"Service call failed: %s\"%e)\n",
    "\n",
    "success, detections, labelled_img = call_process_img(img)\n",
    "\n",
    "display(PILImage.fromarray(cv2.cvtColor(labelled_img, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "print(\"detections\", detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">response success: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "vision_details: \n",
       "  header: \n",
       "    seq: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    stamp: \n",
       "      secs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "      nsecs:         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    frame_id: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "  camera_acquisition_stamp: \n",
       "    secs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    nsecs:         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "  camera: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "  gap_detection: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "  detections: <span style=\"font-weight: bold\">[]</span>\n",
       "  gaps: <span style=\"font-weight: bold\">[]</span>\n",
       "image: \n",
       "  header: \n",
       "    seq: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    stamp: \n",
       "      secs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "      nsecs:         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    frame_id: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "  height: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "  width: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "  encoding: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "  is_bigendian: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "  step: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "  data: <span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "response success: \u001b[3;91mFalse\u001b[0m\n",
       "vision_details: \n",
       "  header: \n",
       "    seq: \u001b[1;36m0\u001b[0m\n",
       "    stamp: \n",
       "      secs: \u001b[1;36m0\u001b[0m\n",
       "      nsecs:         \u001b[1;36m0\u001b[0m\n",
       "    frame_id: \u001b[32m''\u001b[0m\n",
       "  camera_acquisition_stamp: \n",
       "    secs: \u001b[1;36m0\u001b[0m\n",
       "    nsecs:         \u001b[1;36m0\u001b[0m\n",
       "  camera: \u001b[1;36m0\u001b[0m\n",
       "  gap_detection: \u001b[3;91mFalse\u001b[0m\n",
       "  detections: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "  gaps: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "image: \n",
       "  header: \n",
       "    seq: \u001b[1;36m0\u001b[0m\n",
       "    stamp: \n",
       "      secs: \u001b[1;36m0\u001b[0m\n",
       "      nsecs:         \u001b[1;36m0\u001b[0m\n",
       "    frame_id: \u001b[32m''\u001b[0m\n",
       "  height: \u001b[1;36m0\u001b[0m\n",
       "  width: \u001b[1;36m0\u001b[0m\n",
       "  encoding: \u001b[32m''\u001b[0m\n",
       "  is_bigendian: \u001b[1;36m0\u001b[0m\n",
       "  step: \u001b[1;36m0\u001b[0m\n",
       "  data: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def call_get_detection():\n",
    "    timeout = 3 # 2 second timeout\n",
    "    service_path = 'vision/basler/get_detection'\n",
    "    rospy.wait_for_service(service_path, timeout)\n",
    "\n",
    "    # imgmsg = CvBridge().cv2_to_imgmsg(img, encoding=\"bgr8\")\n",
    "    try:\n",
    "        get_detection = rospy.ServiceProxy(service_path, VisionDetection)\n",
    "        response = get_detection(camera=Camera.basler.value, gap_detection=False)\n",
    "        return response\n",
    "    except rospy.ServiceException as e:\n",
    "        print(\"Service call failed: %s\"%e)\n",
    "\n",
    "response = call_get_detection()\n",
    "print(\"response\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
