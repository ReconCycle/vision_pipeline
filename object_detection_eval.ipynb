{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from types import SimpleNamespace\n",
    "import numpy as np\n",
    "import time\n",
    "import commentjson\n",
    "from rich import print\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "\n",
    "from yolact_pkg.utils.augmentations import SSDAugmentation, BaseTransform\n",
    "from yolact_pkg.data.config import Config\n",
    "from yolact_pkg.yolact import Yolact\n",
    "from yolact_pkg.eval import infer, annotate_img, evaluate, parse_args, calc_map, calc_map_classwise, print_maps\n",
    "from yolact_pkg.data.config import MEANS\n",
    "from yolact_pkg.train import train\n",
    "from yolact_pkg.data.coco import COCODetection, detection_collate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"dir()\", dir())\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "dataset = Config({\n",
    "    'name': 'Base Dataset',\n",
    "\n",
    "    # Training images and annotations\n",
    "    'train_images': '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco',\n",
    "    'train_info':   '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco/_train.json',\n",
    "\n",
    "    # Validation images and annotations.\n",
    "    'valid_images': '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco',\n",
    "    'valid_info':   '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco/_test.json',\n",
    "\n",
    "    # Whether or not to load GT. If this is False, eval.py quantitative evaluation won't work.\n",
    "    'has_gt': True,\n",
    "\n",
    "    # A list of names for each of you classes.\n",
    "    'class_names': (\"hca_front\", \"hca_back\", \"hca_side1\", \"hca_side2\", \"battery\", \"pcb\", \"internals\", \"pcb_covered\", \"plastic_clip\"),\n",
    "\n",
    "    # COCO class ids aren't sequential, so this is a bandage fix. If your ids aren't sequential,\n",
    "    # provide a map from category_id -> index in class_names + 1 (the +1 is there because it's 1-indexed).\n",
    "    # If not specified, this just assumes category ids start at 1 and increase sequentially.\n",
    "    'label_map': None\n",
    "})\n",
    "\n",
    "config_override = {\n",
    "    'name': 'yolact_base',\n",
    "\n",
    "    # Dataset stuff\n",
    "    'dataset': dataset,\n",
    "    'num_classes': len(dataset.class_names) + 1,\n",
    "\n",
    "    # Image Size\n",
    "    'max_size': 1100, #! I changed this, was 550\n",
    "    \n",
    "    'save_path': 'data_full/yolact/2022-10-17_kalo_qundis/',\n",
    "    \n",
    "    # we can override args used in eval.py:\n",
    "    'score_threshold': 0.1,\n",
    "    'top_k': 10\n",
    "}\n",
    "\n",
    "# we can override training args here:\n",
    "training_args_override = {\n",
    "    \"batch_size\": 2, #! I changed this, was 8\n",
    "    \"save_interval\": -1, # -1 for saving only at end of the epoch\n",
    "    # \"resume\": \n",
    "    \"validation_size\": 100,\n",
    "}\n",
    "print(\"test\")\n",
    "yolact = Yolact(config_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Inference                               #\n",
    "###########################################\n",
    "\n",
    "yolact.eval()\n",
    "yolact.load_weights(\"./data_limited/yolact/2022-05-02_kalo_qundis/yolact_base_274_202125.pth\")\n",
    "\n",
    "# frame, classes, scores, boxes, masks = yolact.infer(\"/root/datasets/2022-05-02_kalo_qundis/coco/JPEGImages/1066.jpg\")\n",
    "\n",
    "# annotated_img = annotate_img(frame, classes, scores, boxes, masks)\n",
    "\n",
    "# cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
    "# cv2.imshow(\"output\",annotated_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# \n",
    "# todo: evaluation\n",
    "\n",
    "val_dataset = COCODetection(image_path=yolact.cfg.dataset.valid_images,\n",
    "                            info_file=yolact.cfg.dataset.valid_info,\n",
    "                            transform=BaseTransform(MEANS))\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "# print(\"args\", args)\n",
    "all_maps, ap_data = evaluate(yolact, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(yolact.cfg.dataset.class_names), yolact.cfg.dataset.class_names)\n",
    "\n",
    "iou_thresholds = [x / 100 for x in range(50, 100, 5)]\n",
    "\n",
    "all_maps2, _ = calc_map_classwise(yolact, ap_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "784a5e175653632d1d163de77d9b4ab7b2944cd06e5c8be0aa7144cf9611c299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
