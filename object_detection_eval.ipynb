{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from types import SimpleNamespace\n",
    "import numpy as np\n",
    "import time\n",
    "import commentjson\n",
    "from rich import print\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "\n",
    "from yolact_pkg.utils.augmentations import SSDAugmentation, BaseTransform\n",
    "from yolact_pkg.data.config import Config\n",
    "from yolact_pkg.yolact import Yolact\n",
    "from yolact_pkg.eval import infer, annotate_img, evaluate, parse_args, calc_map, calc_map_classwise\n",
    "from yolact_pkg.data.config import MEANS\n",
    "from yolact_pkg.train import train\n",
    "from yolact_pkg.data.coco import COCODetection, detection_collate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"dir()\", dir())\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "dataset = Config({\n",
    "    'name': 'Base Dataset',\n",
    "\n",
    "    # Training images and annotations\n",
    "    'train_images': '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco',\n",
    "    'train_info':   '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco/_train.json',\n",
    "\n",
    "    # Validation images and annotations.\n",
    "    'valid_images': '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco',\n",
    "    'valid_info':   '/home/sruiz/datasets2/reconcycle/2022-05-02_kalo_qundis/coco/_test.json',\n",
    "\n",
    "    # Whether or not to load GT. If this is False, eval.py quantitative evaluation won't work.\n",
    "    'has_gt': True,\n",
    "\n",
    "    # A list of names for each of you classes.\n",
    "    'class_names': (\"hca_front\", \"hca_back\", \"hca_side1\", \"hca_side2\", \"battery\", \"pcb\", \"internals\", \"pcb_covered\", \"plastic_clip\"),\n",
    "\n",
    "    # COCO class ids aren't sequential, so this is a bandage fix. If your ids aren't sequential,\n",
    "    # provide a map from category_id -> index in class_names + 1 (the +1 is there because it's 1-indexed).\n",
    "    # If not specified, this just assumes category ids start at 1 and increase sequentially.\n",
    "    'label_map': None\n",
    "})\n",
    "\n",
    "config_override = {\n",
    "    'name': 'yolact_base',\n",
    "\n",
    "    # Dataset stuff\n",
    "    'dataset': dataset,\n",
    "    'num_classes': len(dataset.class_names) + 1,\n",
    "\n",
    "    # Image Size\n",
    "    'max_size': 1100, #! I changed this, was 550\n",
    "    \n",
    "    'save_path': 'data_full/yolact/2022-10-17_kalo_qundis/',\n",
    "    \n",
    "    # we can override args used in eval.py:\n",
    "    'score_threshold': 0.1,\n",
    "    'top_k': 10\n",
    "}\n",
    "\n",
    "# we can override training args here:\n",
    "training_args_override = {\n",
    "    \"batch_size\": 2, #! I changed this, was 8\n",
    "    \"save_interval\": -1, # -1 for saving only at end of the epoch\n",
    "    # \"resume\": \n",
    "    \"validation_size\": 100,\n",
    "}\n",
    "print(\"test\")\n",
    "yolact = Yolact(config_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Inference                               #\n",
    "###########################################\n",
    "\n",
    "yolact.eval()\n",
    "yolact.load_weights(\"./data_limited/yolact/2022-05-02_kalo_qundis/yolact_base_274_202125.pth\")\n",
    "\n",
    "# frame, classes, scores, boxes, masks = yolact.infer(\"/root/datasets/2022-05-02_kalo_qundis/coco/JPEGImages/1066.jpg\")\n",
    "\n",
    "# annotated_img = annotate_img(frame, classes, scores, boxes, masks)\n",
    "\n",
    "# cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
    "# cv2.imshow(\"output\",annotated_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# \n",
    "# todo: evaluation\n",
    "\n",
    "val_dataset = COCODetection(image_path=yolact.cfg.dataset.valid_images,\n",
    "                            info_file=yolact.cfg.dataset.valid_info,\n",
    "                            transform=BaseTransform(MEANS))\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "# print(\"args\", args)\n",
    "all_maps, ap_data = evaluate(yolact, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(yolact.cfg.dataset.class_names), yolact.cfg.dataset.class_names)\n",
    "\n",
    "iou_thresholds = [x / 100 for x in range(50, 100, 5)]\n",
    "\n",
    "# all_maps2, _ = calc_map_classwise(yolact, ap_data)\n",
    "\n",
    "# print(\"all_maps2\", all_maps2)\n",
    "\n",
    "def calc_map_classwise_copy(net:Yolact, ap_data):\n",
    "    print('Calculating mAP...')\n",
    "    aps = [{'box': [], 'mask': []} for _ in iou_thresholds]\n",
    "\n",
    "    all_class_maps = []\n",
    "    for _class in range(len(net.cfg.dataset.class_names)):\n",
    "        \n",
    "        for iou_idx in range(len(iou_thresholds)):\n",
    "            for iou_type in ('box', 'mask'):\n",
    "                ap_obj = ap_data[iou_type][iou_idx][_class]\n",
    "\n",
    "                if not ap_obj.is_empty():\n",
    "                    aps[iou_idx][iou_type].append(ap_obj.get_ap())\n",
    "\n",
    "        class_map = {'box': OrderedDict(), 'mask': OrderedDict()}\n",
    "\n",
    "        # Looking back at it, this code is really hard to read :/\n",
    "        for iou_type in ('box', 'mask'):\n",
    "            class_map[iou_type]['all'] = 0 # Make this first in the ordereddict\n",
    "            for i, threshold in enumerate(iou_thresholds):\n",
    "                mAP = sum(aps[i][iou_type]) / len(aps[i][iou_type]) * 100 if len(aps[i][iou_type]) > 0 else 0\n",
    "                class_map[iou_type][int(threshold*100)] = mAP\n",
    "            class_map[iou_type]['all'] = (sum(class_map[iou_type].values()) / (len(class_map[iou_type].values())-1))\n",
    "        \n",
    "        # pretty results:\n",
    "        # print(\"class:\", net.cfg.dataset.class_names[_class])\n",
    "        # print_maps(class_map)\n",
    "        \n",
    "        # Put in a prettier format so we can serialize it to json during training\n",
    "        class_map = {k: {j: round(u, 2) for j, u in v.items()} for k, v in class_map.items()}\n",
    "        all_class_maps.append(class_map)\n",
    "    \n",
    "    # work out averages for rotation difference\n",
    "    for _class in range(len(net.cfg.dataset.class_names)):\n",
    "        iou_idx = 0\n",
    "        iou_type = 'rot'\n",
    "        \n",
    "        ap_obj = ap_data[iou_type][iou_idx][_class]\n",
    "        print(\"class:\", net.cfg.dataset.class_names[_class])\n",
    "\n",
    "        rot_diffs = [i[0] for i in ap_obj.data_points]\n",
    "        print(\"rot_diffs\", rot_diffs)\n",
    "        \n",
    "        # ! sometimes the numbers are 0.0, 90.0, 180.0\n",
    "        # ! obviously something is wrong somewhere because that is not correct.\n",
    "\n",
    "        print(\"avg\", np.mean(rot_diffs))\n",
    "        print(\"max\", np.max(rot_diffs))\n",
    "\n",
    "\n",
    "    \n",
    "    return all_class_maps, ap_data\n",
    "\n",
    "all_maps2, _ = calc_map_classwise_copy(yolact, ap_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: compute the rotation accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: compute location accuracy in real world coordinates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "784a5e175653632d1d163de77d9b4ab7b2944cd06e5c8be0aa7144cf9611c299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
